{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e727ca7-a84c-48c2-bf0c-596f9b4f4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval, STATUS_OK\n",
    "\n",
    "from src.lab1.shakespeare_trainer import ShakespeareModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eabe6859-3474-4351-a760-1568adb132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = ShakespeareModule.load_from_checkpoint(\"src/lab1/checkpoints/float-best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a2fe4888-cc36-485a-892d-6e53903f368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully-connected layer with symmetric uniform quantization for weights and activations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        weight_bitwidth: int = 8,\n",
    "        act_bitwidth: int = 8,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight_bitwidth = weight_bitwidth\n",
    "        self.act_bitwidth = act_bitwidth\n",
    "\n",
    "        # Buffers to hold quantized weight and scale\n",
    "        self.register_buffer(\n",
    "            \"qweight\",\n",
    "            torch.zeros(out_features, in_features, dtype=torch.float32),\n",
    "        )\n",
    "        self.register_buffer(\"weight_scale\", torch.ones(1))\n",
    "\n",
    "        # Optional bias stored in float32\n",
    "        if bias:\n",
    "            self.register_buffer(\"bias\", torch.zeros(out_features, dtype=torch.float32))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _quantize_tensor(\n",
    "        x: torch.Tensor, bitwidth: int\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Quantize a tensor to signed integers in [-2^(b-1), 2^(b-1)-1].\n",
    "        Returns (quantized_tensor, scale).\n",
    "        \"\"\"\n",
    "        qmax = 2 ** (bitwidth - 1) - 1\n",
    "        rmax = x.abs().max()\n",
    "        scale = rmax / qmax if rmax > 0 else torch.tensor(1.0, device=x.device)\n",
    "        q = torch.clamp(torch.round(x / scale), -qmax, qmax)\n",
    "        return q, scale\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 1. Quantize activations\n",
    "        qx, act_scale = self._quantize_tensor(x, self.act_bitwidth)\n",
    "\n",
    "        # 2. Integer GEMM\n",
    "        qx = qx.to(self.qweight.dtype)\n",
    "        acc = qx.matmul(self.qweight.t())\n",
    "\n",
    "        # 3. Dequantize\n",
    "        y = acc * act_scale * self.weight_scale\n",
    "\n",
    "        # 4. Add bias if present\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(\"\n",
    "            f\"in={self.in_features}, out={self.out_features}, \"\n",
    "            f\"w_bits={self.weight_bitwidth}, a_bits={self.act_bitwidth})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b9e90f9-def3-4049-a8ee-347a7531dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShakespeareModule(\n",
      "  (model): AutoRegressiveTransformer(\n",
      "    (embedding): Embedding(1024, 256)\n",
      "    (pos_encoder): Embedding(1024, 256)\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0-7): 8 x TransformerBlock(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (qkv_proj): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (activation): GELU(approximate='none')\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(module)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e738bc3e-e9d3-486e-acb6-b34b67240928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_qconfig(module):\n",
    "    blocks = module.model.transformer_blocks\n",
    "    qconfig = {}\n",
    "    for name, module in blocks.named_modules(): \n",
    "        if isinstance(module, nn.Linear): \n",
    "            qconfig[f\"model.transformer_blocks.{name}\"] = 8\n",
    "    return qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18fc4dc5-be5a-4b1b-a2f5-c0f09165bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = ShakespeareModule.load_from_checkpoint(\"src/lab1/checkpoints/float-best.ckpt\")\n",
    "qconfig = get_init_qconfig(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83f3a064-fce8-4697-b112-1eca02719c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodule = quantize_model(module, qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ec8fd9d-edb4-41a4-8b52-ba635f8039a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_function(params): \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,                                      # the number of epochs to train fotraining\n",
    "        accelerator=\"auto\",                                 # the accelerator to use during training\n",
    "        devices=\"auto\",                                     # the devices to use during training\n",
    "        precision=\"16-mixed\",                                        # the precision to use during training \n",
    "    )\n",
    "    module = ShakespeareModule.load_from_checkpoint(\"src/lab1/checkpoints/float-best.ckpt\")\n",
    "    module = quantize_model(module, params)\n",
    "    result = trainer.test(module, verbose=False)\n",
    "    print(result)\n",
    "    return result[0]['test_loss']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd44ae76-908d-4bd9-a5aa-f662d9d6df68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1395901a5502449dbef18a3492890f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': nan, 'test_perplexity': nan}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = ShakespeareModule.load_from_checkpoint(\"src/lab1/checkpoints/float-best.ckpt\")\n",
    "qconfig = get_init_qconfig(module)\n",
    "\n",
    "obj_function(qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d788dbe0-77bd-496c-9158-0c5649faf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {key: hp.choice(key, [2, 4, 8]) for key in qconfig.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c751e464-c702-4d7c-99b7-4e38e416754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d732c39e2214ffaaefec0a0b2d063f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████▎                                                                                   | 1/10 [00:03<00:35,  3.89s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ab4633e754785a4038e42b636724f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██████████████████▌                                                                          | 2/10 [00:07<00:30,  3.87s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54488fabaa154cd19864e8b4b4520f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███████████████████████████▉                                                                 | 3/10 [00:11<00:27,  3.86s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cdfcd41ab040e592dc7caa5831cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████████▏                                                       | 4/10 [00:15<00:23,  3.85s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc9f3dfb2be467184561c83617f2a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████████▌                                              | 5/10 [00:19<00:19,  3.85s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0201d83f6eb4610aff7da7d2b896eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|███████████████████████████████████████████████████████▊                                     | 6/10 [00:23<00:15,  3.86s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a861006ceeab42a895724fa515fa6e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|█████████████████████████████████████████████████████████████████                            | 7/10 [00:27<00:11,  3.86s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec767984b08740628b15c8fd36786357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████████████▍                  | 8/10 [00:30<00:07,  3.86s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4933a8c63001477e9a01680b21452877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████▋         | 9/10 [00:34<00:03,  3.86s/trial, best loss=?]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caf8008ca1d46e886e0c9327c2880c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:38<00:00,  3.86s/trial, best loss=?]\u001b[A\n"
     ]
    },
    {
     "ename": "AllTrialsFailed",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAllTrialsFailed\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m space = {key: hp.choice(key, [\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m qconfig.keys()}\n\u001b[32m      6\u001b[39m trials = Trials()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m best = \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(best)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:540\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    537\u001b[39m     fn = __objective_fmin_wrapper(fn)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[33m\"\u001b[39m\u001b[33mfmin\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(trials_save_file):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/hyperopt/base.py:671\u001b[39m, in \u001b[36mTrials.fmin\u001b[39m\u001b[34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/hyperopt/fmin.py:593\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials.trials) == \u001b[32m0\u001b[39m:\n\u001b[32m    590\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    591\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThere are no evaluation tasks, cannot return argmin of task losses.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    592\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmin\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials) > \u001b[32m0\u001b[39m:\n\u001b[32m    595\u001b[39m     \u001b[38;5;66;03m# Only if there are some successful trail runs, return the best point in\u001b[39;00m\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# the evaluation space\u001b[39;00m\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m space_eval(space, trials.argmin)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/hyperopt/base.py:620\u001b[39m, in \u001b[36mTrials.argmin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34margmin\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m     best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m\n\u001b[32m    621\u001b[39m     vals = best_trial[\u001b[33m\"\u001b[39m\u001b[33mmisc\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mvals\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# unpack the one-element lists to values\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;66;03m# and skip over the 0-element lists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/hyperopt/base.py:611\u001b[39m, in \u001b[36mTrials.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    605\u001b[39m candidates = [\n\u001b[32m    606\u001b[39m     t\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trials\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m] == STATUS_OK \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isnan(t[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    609\u001b[39m ]\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AllTrialsFailed\n\u001b[32m    612\u001b[39m losses = [\u001b[38;5;28mfloat\u001b[39m(t[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mAllTrialsFailed\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "\n",
    "space = {key: hp.choice(key, [2, 4, 8]) for key in qconfig.keys()}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=obj_function,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials,\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b412a-b517-46a4-b375-fa47c4ab4887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcf5d0-350f-49d9-8044-4ac7417ba3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05740a34-df9f-44a0-9746-b26a5fbb8c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
